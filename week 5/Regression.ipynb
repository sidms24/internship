{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOuigqFa1zCYhxNTrb7w2/R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidms24/internship/blob/main/week%205/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARJl6tkeO_pK",
        "outputId": "da7788bf-3eac-4c2a-9bc7-eb2c5c154ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m2.8/3.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IidkW6mL09NO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import Bio\n",
        "from Bio import SeqIO\n",
        "token = userdata.get('GITHUB_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "url = \"https://raw.githubusercontent.com/sidms24/internship/refs/heads/main/week%205/latents.csv\"\n",
        "filename = \"latent.csv\"\n",
        "curl_output_latents = os.system(f\"curl -H 'Authorization: token {token}' {url} > {filename}\")\n",
        "print(f\"Curl output for latents.csv: {curl_output_latents}\")\n",
        "latents = pd.read_csv(\"latent.csv\", index_col=0)\n",
        "\n",
        "gp_url = \"https://raw.githubusercontent.com/sidms24/internship/refs/heads/main/week%205/Gp_ili_consult_100k.csv\"\n",
        "gp_filename = \"gp.csv\"\n",
        "curl_output_gp = os.system(f\"curl -H 'Authorization: token {token}' {gp_url} > {gp_filename}\")\n",
        "print(f\"Curl output for gp.csv: {curl_output_gp}\")\n",
        "gp = pd.read_csv(\"gp.csv\", skiprows = 4)\n",
        "\n",
        "seq_url = \"https://raw.githubusercontent.com/sidms24/internship/refs/heads/main/week%205/sequences(all).csv\"\n",
        "seq_filename = \"sequences.csv\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(seq_url, headers={'Authorization': f'token {token}'})\n",
        "    response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "    with open(seq_filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"Downloaded {seq_filename} successfully.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading {seq_filename}: {e}\")\n",
        "\n",
        "\n",
        "encoder_url = \"https://raw.githubusercontent.com/sidms24/internship/refs/heads/main/week%205/encoder_weights.pth\"\n",
        "encoder_filename = \"encoder.pth\"\n",
        "os.system(f\"curl -H 'Authorization: token {token}' {encoder_url} > {encoder_filename}\")\n",
        "\n",
        "sequences_all_url = \"https://raw.githubusercontent.com/sidms24/internship/refs/heads/main/week%205/sequences(all).fasta\"\n",
        "sequences_all_filename = \"sequences_all.fasta\"\n",
        "try:\n",
        "    response = requests.get(sequences_all_url, headers={'Authorization': f'token {token}'})\n",
        "    response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "    with open(sequences_all_filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"Downloaded {sequences_all_filename} successfully.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading {sequences_all_filename}: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUDOqg9e2QWL",
        "outputId": "3310a513-4f4e-4177-fc03-713e824c7f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Curl output for latents.csv: 0\n",
            "Curl output for gp.csv: 0\n",
            "Downloaded sequences.csv successfully.\n",
            "Downloaded sequences_all.fasta successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = pd.read_csv(\"sequences.csv\")\n",
        "seq.columns\n",
        "seq.isna().sum()\n",
        "s = seq.drop(columns = ['Isolate', 'Tissue_Specimen_Source'], axis = 1)\n",
        "s['Collection_Date'] = pd.to_datetime(s['Collection_Date'], errors='coerce')\n",
        "s['Release_Date'] = pd.to_datetime(s['Release_Date'] )\n",
        "\n",
        "def get_season(date):\n",
        "  if date.month >= 9:\n",
        "    return f\"{date.year}/{str(date.year + 1)[-2:]}\"\n",
        "  elif date.month <= 8:\n",
        "    return f\"{date.year - 1}/{str(date.year)[-2:]}\"\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "s['season'] = s['Collection_Date'].apply(get_season)\n",
        "s['year'] =  s['Collection_Date'].apply(lambda x: x.date().year)\n",
        "\n",
        "for i in range(len(s)):\n",
        "  l = s.iloc[i, 1].split(\" \")\n",
        "  a = s.iloc[i, 3]\n",
        "  if len(l) > 3 and a is np.nan:\n",
        "    o = l[-1].split(\"(\")[-1]\n",
        "    s.iloc[i,3] = o.strip(')')\n",
        "s.dropna(inplace=True)\n",
        "s.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "lqpwiL8hJFzY"
      },
      "execution_count": 690,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(seq,max_length = 2366):\n",
        "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], \"T\": [0, 0, 0, 1]}\n",
        "    one_hot = [mapping.get(base, [0, 0, 0, 0]) for base in seq]\n",
        "\n",
        "    # 2. Calculate the amount of padding needed\n",
        "    padding_needed = max_length - len(one_hot)\n",
        "\n",
        "    # 3. Create the padding (a list of zero vectors)\n",
        "    #    Ensure padding_needed is not negative if a sequence is too long.\n",
        "    if padding_needed > 0:\n",
        "        padding = [[0, 0, 0, 0]] * padding_needed\n",
        "        one_hot.extend(padding)\n",
        "\n",
        "    # Optional: Truncate sequences that are longer than max_length\n",
        "    elif padding_needed < 0:\n",
        "        one_hot = one_hot[:max_length]\n",
        "\n",
        "    return one_hot\n",
        "l = []\n",
        "for record in SeqIO.parse(\"sequences_all.fasta\", \"fasta\"):\n",
        "  l.append({\"Accession\": record.id.split('.')[0], \"Sequence\": str(record.seq)})\n",
        "seq2 = pd.DataFrame(l)\n",
        "s = pd.merge(s, seq2, on = \"Accession\", how = \"inner\")\n",
        "s[\"sequence_one_hot\"] = s[\"Sequence\"].apply(one_hot_encode)"
      ],
      "metadata": {
        "id": "Uw64CG-VOBOr"
      },
      "execution_count": 509,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "     super().__init__()\n",
        "     self.encoder = nn.Sequential(\n",
        "         nn.Linear(input_dim, hidden_dim),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(hidden_dim // 4, hidden_dim // 8),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(hidden_dim // 8, latent_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.encoder(x)\n",
        "\n",
        "input_dim = 2366 * 4  # Based on the one-hot encoding length and number of bases\n",
        "hidden_dim = 128 # Set hidden_dim to 128 based on the error message\n",
        "latent_dim = 2    # Based on Latent_dim1 and Latent_dim2\n",
        "\n",
        "X= np.array([np.array(seq) for seq in s['sequence_one_hot'].values])\n",
        "X= np.array([seq.flatten() for seq in X])\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "model = Encoder(input_dim, hidden_dim, latent_dim)\n",
        "model.load_state_dict(torch.load(\"encoder.pth\", map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  latent = model(X)\n"
      ],
      "metadata": {
        "id": "8JBVgA4MP-V0"
      },
      "execution_count": 511,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent = latent.cpu().numpy()\n",
        "s['Latent'] = latent.tolist()\n",
        "s[\"latent_dim1\"] = s[\"Latent\"].apply(lambda x: x[0])\n",
        "s[\"latent_dim2\"] = s[\"Latent\"].apply(lambda x: x[1])\n",
        "s[\"latent_dim\"] =  s[\"Latent\"].apply(lambda x: np.sqrt((x[0]**2) + (x[1]**2)))"
      ],
      "metadata": {
        "id": "ORysdP26RoZd"
      },
      "execution_count": 691,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2 = s\n",
        "s = s[s['Genotype'] != \"H3\"]\n",
        "s = s[s['Genotype'] != \"unknown\"]\n"
      ],
      "metadata": {
        "id": "AWJqCAFZsFHi"
      },
      "execution_count": 692,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mortality = pd.read_csv(\"Trends (2).csv\")\n",
        "mortality = mortality[[\"Time period Sortable\",\"Value\"]]\n",
        "mortality[\"year\"] = mortality['Time period Sortable'].apply(lambda x:int(x /10000))\n",
        "mortality = mortality.drop(\"Time period Sortable\", axis=1)\n",
        "mortality = mortality.set_index('year')"
      ],
      "metadata": {
        "id": "ZDaAtE3PTUDl"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "s1 = s2.groupby(['year', 'Genotype', 'Segment'])[['latent_dim']].expanding().mean()\n",
        "s1 = s1.reset_index()\n",
        "s1 = pd.merge(s1, mortality, on='year', how = 'inner')\n",
        "s1 = s1.drop(columns = [\"level_3\"])\n",
        "\n",
        "\n",
        "s1[\"log_value\"] = np.log(s1['Value'])\n",
        "\n",
        "X = s1.drop(columns=['Value', 'log_value'])\n",
        "X = pd.get_dummies(X, columns=['Segment', 'Genotype'], drop_first=True, dtype=int)\n",
        "y = s1[\"log_value\"]\n",
        "\n",
        "\n",
        "X_diff = X.diff().dropna()\n",
        "y_diff = y.diff().dropna()\n",
        "\n",
        "X_diff, y_diff = X_diff.align(y_diff, join='inner', axis=0)\n",
        "\n",
        "model = sm.OLS(y_diff, X_diff).fit(cov_type='HC1')\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# kinda make sense the"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COILt6Q4Yfb_",
        "outputId": "9e1c4f6b-3921-48d8-c9f9-a05edfb0d5ac"
      },
      "execution_count": 729,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 OLS Regression Results                                \n",
            "=======================================================================================\n",
            "Dep. Variable:              log_value   R-squared (uncentered):                   0.582\n",
            "Model:                            OLS   Adj. R-squared (uncentered):              0.581\n",
            "Method:                 Least Squares   F-statistic:                              4659.\n",
            "Date:                Thu, 10 Jul 2025   Prob (F-statistic):                        0.00\n",
            "Time:                        14:52:00   Log-Likelihood:                          34319.\n",
            "No. Observations:                6902   AIC:                                 -6.861e+04\n",
            "Df Residuals:                    6888   BIC:                                 -6.851e+04\n",
            "Df Model:                          14                                                  \n",
            "Covariance Type:                  HC1                                                  \n",
            "====================================================================================\n",
            "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "year                -0.0100      0.003     -3.582      0.000      -0.015      -0.005\n",
            "latent_dim        6.831e-05   5.08e-05      1.345      0.179   -3.12e-05       0.000\n",
            "Segment_2.0         -0.0025      0.003     -0.716      0.474      -0.009       0.004\n",
            "Segment_3.0         -0.0031      0.006     -0.551      0.582      -0.014       0.008\n",
            "Segment_4.0         -0.0002      0.005     -0.044      0.965      -0.011       0.011\n",
            "Segment_5.0          0.0018      0.005      0.386      0.700      -0.008       0.011\n",
            "Segment_6.0          0.0058      0.004      1.468      0.142      -0.002       0.014\n",
            "Segment_7.0          0.0087      0.005      1.830      0.067      -0.001       0.018\n",
            "Segment_8.0          0.0123      0.006      1.980      0.048       0.000       0.024\n",
            "Genotype_H1N1        0.0019      0.010      0.182      0.856      -0.018       0.022\n",
            "Genotype_H1N2       -0.0164      0.016     -1.006      0.315      -0.048       0.016\n",
            "Genotype_H3          0.0107      0.011      0.955      0.340      -0.011       0.033\n",
            "Genotype_H3N2        0.0195      0.013      1.462      0.144      -0.007       0.046\n",
            "Genotype_unknown     0.0193      0.017      1.111      0.266      -0.015       0.053\n",
            "==============================================================================\n",
            "Omnibus:                    13701.346   Durbin-Watson:                   2.034\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        244622199.580\n",
            "Skew:                         -15.082   Prob(JB):                         0.00\n",
            "Kurtosis:                     924.794   Cond. No.                         600.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
            "[2] Standard Errors are heteroscedasticity robust (HC1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_eddlZ9t0UEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}